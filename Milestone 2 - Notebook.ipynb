{"cells":[{"cell_type":"markdown","metadata":{"id":"hWQC8iCE2_-o"},"source":["# **Milestone 2**"]},{"cell_type":"markdown","metadata":{"id":"DYdEI31whyE-"},"source":["We have built two Convolutional Neural Network architectures in Milestone 1. Here, we will further try to achieve better performance by increasing the number of parameters/weights. Therefore, we will start this Milestone with three popular Transfer Learning architectures, namely, VGG16, ResNet v2, and Efficient Net. Please feel free to explore other pre-trained models as well. Link to Keras documentation for pre-trained models - https://keras.io/api/applications/"]},{"cell_type":"markdown","metadata":{"id":"HDM89XHyCxrA"},"source":["## **Mounting the Drive**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24526,"status":"ok","timestamp":1671153426352,"user":{"displayName":"Thomas Abbott","userId":"02506443549812250036"},"user_tz":300},"id":"JQi_degJC3dm","outputId":"f7d17346-661c-41d1-ba9d-808d4e1238b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Mounting the drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"UC8-yLUUCcWh"},"source":["## **Importing the Libraries**"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4005,"status":"ok","timestamp":1671153430353,"user":{"displayName":"Thomas Abbott","userId":"02506443549812250036"},"user_tz":300},"id":"30fd2144"},"outputs":[],"source":["import zipfile\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import os\n","\n","# Importing Deep Learning Libraries\n","\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D, LeakyReLU\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop"]},{"cell_type":"markdown","metadata":{"id":"nCqJk2XpCnJi"},"source":["### **Loading the Data**"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3536,"status":"ok","timestamp":1671153433884,"user":{"displayName":"Thomas Abbott","userId":"02506443549812250036"},"user_tz":300},"id":"sMfr4tK04C0o"},"outputs":[],"source":["# Storing the path of the data file from the Google drive\n","path = '/content/drive/MyDrive/Facial_emotion_images.zip'\n","\n","# The data is provided as a zip file so we need to extract the files from the zip file\n","with zipfile.ZipFile(path, 'r') as zip_ref:\n","    zip_ref.extractall()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1671153433884,"user":{"displayName":"Thomas Abbott","userId":"02506443549812250036"},"user_tz":300},"id":"4e89d1c7"},"outputs":[],"source":["picture_size = 48\n","folder_path = \"Facial_emotion_images/\""]},{"cell_type":"markdown","metadata":{"id":"boQi7epI3Lsu"},"source":["## **Transfer Learning Architectures**\n","\n","In this section, we will create several Transfer Learning architectures. For the pre-trained models, we will select three popular architectures namely, VGG16, ResNet v2, and Efficient Net. The difference between these architectures and the previous architectures is that these will require 3 input channels while the earlier ones worked on 'grayscale' images. Therefore, we need to create new DataLoaders."]},{"cell_type":"markdown","metadata":{"id":"J7NKTPgdEsgt"},"source":["### **Creating our Data Loaders for Transfer Learning Architectures**\n","\n","In this section, we are creating data loaders that we will use as inputs to our Neural Network. Unlike in Milestone 1, we will have to go with color_mode = 'rgb' as this is the required format for the transfer learning architectures."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":811,"status":"ok","timestamp":1671153434682,"user":{"displayName":"Thomas Abbott","userId":"02506443549812250036"},"user_tz":300},"id":"d97fee2d","outputId":"8bd95dc3-1bef-43b4-d2aa-dc10f359bf32"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 15109 images belonging to 4 classes.\n","Found 4977 images belonging to 4 classes.\n","Found 128 images belonging to 4 classes.\n"]}],"source":["batch_size  = 32\n","img_size = 48\n","\n","datagen_train = ImageDataGenerator(horizontal_flip = True,\n","                                    brightness_range = (0., 2.),\n","                                    rescale = 1./255,\n","                                    shear_range = 0.3)\n","\n","train_set = datagen_train.flow_from_directory(folder_path + \"train\",\n","                                              target_size = (img_size, img_size),\n","                                              color_mode = 'rgb',\n","                                              batch_size = batch_size,\n","                                              class_mode = 'categorical',\n","                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n","                                              shuffle = True)\n","\n","datagen_validation = ImageDataGenerator(horizontal_flip = True,\n","                                    brightness_range = (0., 2.),\n","                                    rescale = 1./255,\n","                                    shear_range = 0.3)\n","\n","validation_set = datagen_validation.flow_from_directory(folder_path + \"validation\",\n","                                              target_size = (img_size, img_size),\n","                                              color_mode = 'rgb',\n","                                              batch_size = batch_size,\n","                                              class_mode = 'categorical',\n","                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n","                                              shuffle = True)\n","\n","\n","datagen_test = ImageDataGenerator(horizontal_flip = True,\n","                                    brightness_range = (0., 2.),\n","                                    rescale = 1./255,\n","                                    shear_range = 0.3)\n","\n","test_set = datagen_test.flow_from_directory(folder_path + \"test\",\n","                                              target_size = (img_size, img_size),\n","                                              color_mode = 'rgb',\n","                                              batch_size = batch_size,\n","                                              class_mode = 'categorical',\n","                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n","                                              shuffle = True)"]},{"cell_type":"markdown","metadata":{"id":"vaUYQdkf7pDG"},"source":["## **VGG16 Model**"]},{"cell_type":"markdown","metadata":{"id":"ThCSNrWC4HW0"},"source":["### **Importing the VGG16 Architecture**"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1704,"status":"ok","timestamp":1671153436380,"user":{"displayName":"Thomas Abbott","userId":"02506443549812250036"},"user_tz":300},"id":"7c83c83e","outputId":"506496cb-fd58-4052-de14-dd5ba7087872"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras import Model\n","\n","vgg = VGG16(include_top = False, weights = 'imagenet', input_shape = (48, 48, 3))\n","vgg.summary()"]},{"cell_type":"markdown","metadata":{"id":"X76HMyZX4edM"},"source":["### **Model Building**\n","\n","* In this model, we will import till the **'block5_pool'** layer of the VGG16 model. You can scroll down in the model summary and look for 'block5_pool'. You can choose any other layer as well.\n","* Then we will add a Flatten layer, which receives the output of the 'block5_pool' layer as its input.\n","* We will add a few Dense layers and use 'relu' activation function on them.\n","* You may use Dropout and BatchNormalization layers as well.\n","* Then we will add our last dense layer, which must have 4 neurons and a 'softmax' activation function."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1671153436381,"user":{"displayName":"Thomas Abbott","userId":"02506443549812250036"},"user_tz":300},"id":"8b123bc6"},"outputs":[],"source":["transfer_layer = vgg.get_layer('block5_pool')\n","vgg.trainable = False\n","\n","# Add classification layers on top of it\n","\n","# Flattenning the output from the 3rd block of the VGG16 model\n","x = Flatten()(transfer_layer.output)\n","\n","# Adding a Dense layer with 256 neurons\n","x = Dense(256, activation = 'relu')(x)\n","\n","# Add a Dense Layer with 128 neurons\n","x = Dense(128, activation = 'relu')(x)\n","\n","# Add a DropOut layer with Drop out ratio of 0.3\n","x = Dropout(rate=0.3)(x)\n","\n","# Add a Dense Layer with 64 neurons\n","x = Dense(64, activation = 'relu')(x)\n","\n","# Add a Batch Normalization layer\n","x = BatchNormalization()(x)\n","\n","# Adding the final dense layer with 4 neurons and use 'softmax' activation\n","pred = Dense(4, activation='softmax')(x)\n","\n","vggmodel = Model(vgg.input, pred) # Initializing the model"]},{"cell_type":"markdown","metadata":{"id":"t6vK7u7w8GsM"},"source":["### **Compiling and Training the VGG16 Model**"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1671153436382,"user":{"displayName":"Thomas Abbott","userId":"02506443549812250036"},"user_tz":300},"id":"86b249f1"},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","\n","checkpoint = ModelCheckpoint(\"./vggmodel.h5\", monitor = 'val_loss', verbose = 1, save_best_only = True, mode = 'max')\n","\n","early_stopping = EarlyStopping(monitor = 'val_loss',\n","                          min_delta = 0,\n","                          patience = 3,\n","                          verbose = 1,\n","                          restore_best_weights = True\n","                          )\n","\n","reduce_learningrate = ReduceLROnPlateau(monitor = 'val_loss',\n","                              factor = 0.2,\n","                              patience = 3,\n","                              verbose = 1,\n","                              min_delta = 0.0001)\n","\n","callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n","\n","epochs = 20"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1671153436383,"user":{"displayName":"Thomas Abbott","userId":"02506443549812250036"},"user_tz":300},"id":"0PN6ghMOGGgf"},"outputs":[],"source":["# Write your code to compile the vggmodel. Use categorical crossentropy as the loss function, Adam Optimizer with 0.001 learning rate, and set metrics to 'accuracy'. \n","from tensorflow.keras.losses import categorical_crossentropy\n","\n","vggmodel.compile(optimizer=Adam(learning_rate = 0.001), loss=categorical_crossentropy, metrics='accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"893285ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","473/473 [==============================] - 509s 1s/step - loss: 1.3214 - accuracy: 0.3859 - val_loss: 1.2369 - val_accuracy: 0.4314\n","Epoch 2/20\n","473/473 [==============================] - 496s 1s/step - loss: 1.2055 - accuracy: 0.4467 - val_loss: 1.2280 - val_accuracy: 0.4356\n","Epoch 3/20\n","473/473 [==============================] - 498s 1s/step - loss: 1.1863 - accuracy: 0.4652 - val_loss: 1.1641 - val_accuracy: 0.4702\n","Epoch 4/20\n","473/473 [==============================] - 499s 1s/step - loss: 1.1707 - accuracy: 0.4713 - val_loss: 1.2645 - val_accuracy: 0.4217\n","Epoch 5/20\n","473/473 [==============================] - 500s 1s/step - loss: 1.1606 - accuracy: 0.4775 - val_loss: 1.1400 - val_accuracy: 0.4927\n","Epoch 6/20\n","473/473 [==============================] - 501s 1s/step - loss: 1.1463 - accuracy: 0.4849 - val_loss: 1.1935 - val_accuracy: 0.4402\n","Epoch 7/20\n","473/473 [==============================] - 502s 1s/step - loss: 1.1390 - accuracy: 0.4933 - val_loss: 1.1251 - val_accuracy: 0.4999\n","Epoch 8/20\n"," 34/473 [=\u003e............................] - ETA: 5:45 - loss: 1.1423 - accuracy: 0.4761"]}],"source":["# Write your code to fit your model. Use train_set as the training data and validation_set as the validation data. Train the model for 20 epochs.\n","history = vggmodel.fit(train_set, validation_data = validation_set, epochs = 20)\n"]},{"cell_type":"markdown","metadata":{"id":"Un-19jPckK07"},"source":["### **Evaluating the VGG16 model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6Y_bSLCkcvr"},"outputs":[],"source":["# Write your code to evaluate model performance on the test set\n","vggmodel_eval = vggmodel.evaluate(test_set) \n","\n","# Model.evaluate() outputs the test loss and the test accuracy, hence:\n","print('VGG Test loss:', vggmodel_eval[0]) \n","print('VGG Test accuracy:', vggmodel_eval[1])"]},{"cell_type":"markdown","metadata":{"id":"tW6kPSky59Gv"},"source":["**Think About It:**\n","\n","- What do you infer from the general trend in the training performance? \n","- Is the training accuracy consistently improving? \n","- Is the validation accuracy also improving similarly?"]},{"cell_type":"markdown","metadata":{"id":"YuTi6OAx8q_r"},"source":["**Observations and Insights: The general trend in the training performance shows that the model's accuracy is gradually increasing and the loss is gradually decreasing. The training accuracy is steadily improving however, the validation accuracy fluctuates more. The validation accuracy is generally improving but not as monotonically as the training accuracy.**"]},{"cell_type":"markdown","metadata":{"id":"AfC2Kx0v7Sa1"},"source":["**Note: You can even go back and build your own architecture on top of the VGG16 Transfer layer and see if you can improve the performance**"]},{"cell_type":"markdown","metadata":{"id":"E0Mew4Cc7u7k"},"source":["## **ResNet V2 Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"568a5c9a","scrolled":false},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow.keras.applications as ap\n","from tensorflow.keras import Model\n","\n","Resnet = ap.ResNet101(include_top = False, weights = \"imagenet\", input_shape=(48,48,3))\n","Resnet.summary()"]},{"cell_type":"markdown","metadata":{"id":"ay4RedCQlL4O"},"source":["### **Model Building**\n","\n","* In this model, we will import till the **'conv5_block3_add'** layer of the ResNet model. You can scroll down in the model summary and look for 'conv5_block3_add'. You can choose any other layer as well.\n","* Then we will add a Flatten layer, which receives the output of the 'conv5_block3_add' layer as its input.\n","* We will add a few Dense layers and use 'relu' activation function on them.\n","* You may use Dropout and BatchNormalization layers as well.\n","* Then we will add our last dense layer, which must have 4 neurons and a 'softmax' activation function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"911d3335"},"outputs":[],"source":["transfer_layer_Resnet = Resnet.get_layer('conv5_block3_add')\n","Resnet.trainable=False\n","\n","# Add classification layers on top of it\n","\n","# Flattenning the output from the 3rd block of the VGG16 model\n","x = Flatten()(transfer_layer_Resnet.output)\n","\n","# Add a Dense layer with 256 neurons\n","x = Dense(256, activation = 'relu')(x)\n","\n","# Add a Dense Layer with 128 neurons\n","x = Dense(128, activation = 'relu')(x)\n","\n","# Add a DropOut layer with Drop out ratio of 0.3\n","x = Dropout(rate=0.3)(x)\n","\n","# Add a Dense Layer with 64 neurons\n","x = Dense(64, activation = 'relu')(x)\n","\n","# Add a Batch Normalization layer\n","x = BatchNormalization()(x)\n","\n","# Add the final dense layer with 4 neurons and use a 'softmax' activation\n","pred = Dense(4, activation = 'softmax')(x)\n","\n","resnetmodel = Model(Resnet.input, pred) # Initializing the model"]},{"cell_type":"markdown","metadata":{"id":"Tmtcd1ZElpJy"},"source":["### **Compiling and Training the Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fe959789"},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","\n","checkpoint = ModelCheckpoint(\"./Resnetmodel.h5\", monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n","\n","early_stopping = EarlyStopping(monitor = 'val_loss',\n","                          min_delta = 0,\n","                          patience = 3,\n","                          verbose = 1,\n","                          restore_best_weights = True\n","                          )  # Write your code here. You may play around with the hyperparameters if you wish.\n","\n","\n","reduce_learningrate = ReduceLROnPlateau(monitor = 'val_loss',\n","                              factor = 0.2,\n","                              patience = 3,\n","                              verbose = 1,\n","                              min_delta = 0.0001)\n"," # Write your code here. You may play around with the hyperparameters if you wish.\n","\n","\n","callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n","\n","epochs = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"641VUEtvGaLW"},"outputs":[],"source":["# Write your code to compile your resnetmodel. Use categorical crossentropy as your loss function, Adam Optimizer with 0.001 learning rate, and set your metrics to 'accuracy'. \n","\n","resnetmodel.compile(optimizer=Adam(learning_rate = 0.001), loss=categorical_crossentropy, metrics='accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mBZRmTFLIRtS"},"outputs":[],"source":["# Write your code to fit your model. Use train_set as your training data and validation_set as your validation data. Train your model for 20 epochs.\n","\n","history = resnetmodel.fit(train_set, validation_data = validation_set, epochs = 20)"]},{"cell_type":"markdown","metadata":{"id":"McHEzBlhxw39"},"source":["### **Evaluating the ResNet Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IEl6IQf0xwci"},"outputs":[],"source":["# Write your code to evaluate model performance on the test set\n","resnetmodel_eval = resnetmodel.evaluate(test_set) \n","\n","# Model.evaluate() outputs the test loss and the test accuracy, hence:\n","print('Resnet Test loss:', resnetmodel_eval[0]) \n","print('Resnet Test accuracy:', resnetmodel_eval[1])"]},{"cell_type":"markdown","metadata":{"id":"3htKZRdomiOY"},"source":["**Observations and Insights: The general trend in the training performance shows that the model's accuracy is not improving over number of epochs. The training accuracy is and validation accuracy fluctuate between 0.1 and 0.4 but do not show signs of improvement. The training and validation loss also fluctuate, specifically between 1.35 and 1.45.**\n","\n","**Note: You can even go back and build your own architecture on top of the ResNet Transfer layer and see if you can improve the performance.**"]},{"cell_type":"markdown","metadata":{"id":"FmnDG4ZbncoR"},"source":["## **EfficientNet Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"613c7a71"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow.keras.applications as ap\n","from tensorflow.keras import Model\n","EfficientNet = ap.EfficientNetV2B2(include_top=False,weights=\"imagenet\", input_shape= (48, 48, 3))\n","\n","EfficientNet.summary()"]},{"cell_type":"markdown","metadata":{"id":"6kDNE8pVngqC"},"source":["### **Model Building**\n","\n","**Build your own Architecture on top of the transfer layer. Be sure to have a Flatten layer after your transfer layer and also make sure you have 4 neurons and softmax activation function in your last dense layer**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2b27a6e1"},"outputs":[],"source":["transfer_layer_EfficientNet = EfficientNet.get_layer('block6e_expand_activation')\n","EfficientNet.trainable = False\n","\n","# Add your Flatten layer.\n","# Flattenning the output from the 6th block of the EfficientNet model\n","x = Flatten()(transfer_layer_EfficientNet.output)\n","\n","# Add your Dense layers and/or BatchNormalization and Dropout layers\n","x = Dense(256, activation = 'relu')(x)\n","x = Dense(128, activation = 'relu')(x)\n","x = Dropout(rate=0.3)(x)\n","x = Dense(64, activation = 'relu')(x)\n","x = BatchNormalization()(x)\n","\n","# Add your final Dense layer with 4 neurons and softmax activation function.\n","pred = Dense(4, activation = 'softmax')(x)\n","\n","Efficientnetmodel = Model(EfficientNet.input, pred) # Initializing the model"]},{"cell_type":"markdown","metadata":{"id":"hVv4Df_In32Y"},"source":["### **Compiling and Training the Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dc326cd3"},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","\n","checkpoint = ModelCheckpoint(\"./Efficientnetmodel.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","\n","early_stopping = EarlyStopping(monitor = 'val_loss',\n","                          min_delta = 0,\n","                          patience = 3,\n","                          verbose = 1,\n","                          restore_best_weights = True\n","                          )  # Write your code here. You may play around with the hyperparameters if you wish.\n","\n","reduce_learningrate =  ReduceLROnPlateau(monitor = 'val_loss',\n","                              factor = 0.2,\n","                              patience = 3,\n","                              verbose = 1,\n","                              min_delta = 0.0001) # Write your code here. You may play around with the hyperparameters if you wish.\n","\n","callbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n","\n","epochs = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U13gspW8I-e3"},"outputs":[],"source":["# Write your code to compile your Efficientnetmodel. Use categorical crossentropy as your loss function, Adam Optimizer with 0.001 learning rate, and set your metrics to 'accuracy'.\n","\n","Efficientnetmodel.compile(optimizer=Adam(learning_rate = 0.001), loss=categorical_crossentropy, metrics='accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Doy0fkOwIew_"},"outputs":[],"source":["# Write your code to fit your model. Use train_set as your training data and validation_set as your validation data. Train your model for 20 epochs.\n","\n","history = Efficientnetmodel.fit(train_set, validation_data = validation_set, epochs = 20)"]},{"cell_type":"markdown","metadata":{"id":"2xjrzYpgoQnN"},"source":["### **Evaluating the EfficientnetNet Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJVFenvnoQnN"},"outputs":[],"source":["# Write your code to evaluate the model performance on the test set\n","\n","Efficientnetmodel_eval = Efficientnetmodel.evaluate(test_set) \n","\n","# Model.evaluate() outputs the test loss and the test accuracy, hence:\n","print('EfficientNet Test loss:', Efficientnetmodel_eval[0]) \n","print('EfficientNet Test accuracy:', Efficientnetmodel_eval[1])"]},{"cell_type":"markdown","metadata":{"id":"kWlk14FOoQnN"},"source":["**Observations and Insights:__**\n","\n","**Note: You can even go back and build your own architecture on top of the VGG16 Transfer layer and see if you can improve the performance.**"]},{"cell_type":"markdown","metadata":{"id":"fk6QAcv5odNF"},"source":["**Think About It:**\n","\n","* What is your overall performance of these Transfer Learning Architectures? Can we draw a comparison of these models' performances. Are we satisfied with the accuracies that we have received?\n","* Do you think our issue lies with 'rgb' color_mode?"]},{"cell_type":"markdown","metadata":{"id":"-EH3atQP8q_v"},"source":["Now that we have tried multiple pre-trained models, let's build a complex CNN architecture and see if we can get better performance."]},{"cell_type":"markdown","metadata":{"id":"SjKlBaZDpWoV"},"source":["## **Building a Complex Neural Network Architecture**"]},{"cell_type":"markdown","metadata":{"id":"-bMFUj3Fpe75"},"source":["In this section, we will build a more complex Convolutional Neural Network Model that has close to as many parameters as we had in our Transfer Learning Models. However, we will have only 1 input channel for our input images."]},{"cell_type":"markdown","metadata":{"id":"ejGfyYSbtx-F"},"source":["## **Creating our Data Loaders**\n","\n","In this section, we are creating data loaders which we will use as inputs to the more Complicated Convolutional Neural Network. We will go ahead with color_mode = 'grayscale'."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xj1hM5_ttx-F"},"outputs":[],"source":["batch_size  = 32\n","img_size = 48\n","\n","datagen_train = ImageDataGenerator(horizontal_flip = True,\n","                                    brightness_range = (0., 2.),\n","                                    rescale = 1./255,\n","                                    shear_range = 0.3)\n","\n","train_set = datagen_train.flow_from_directory(folder_path + \"train\",\n","                                              target_size = (img_size, img_size),\n","                                              color_mode = 'grayscale',\n","                                              batch_size = batch_size,\n","                                              class_mode = 'categorical',\n","                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n","                                              shuffle = True)\n","\n","\n","datagen_validation = ImageDataGenerator(horizontal_flip = True,\n","                                    brightness_range = (0., 2.),\n","                                    rescale = 1./255,\n","                                    shear_range = 0.3)\n","\n","validation_set = datagen_validation.flow_from_directory(folder_path + \"validation\",\n","                                              target_size = (img_size, img_size),\n","                                              color_mode = 'grayscale',\n","                                              batch_size = batch_size,\n","                                              class_mode = 'categorical',\n","                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n","                                              shuffle = True)\n","\n","datagen_test = ImageDataGenerator(horizontal_flip = True,\n","                                    brightness_range = (0., 2.),\n","                                    rescale = 1./255,\n","                                    shear_range = 0.3)\n","\n","test_set = datagen_test.flow_from_directory(folder_path + \"test\",\n","                                              target_size = (img_size, img_size),\n","                                              color_mode = 'grayscale',\n","                                              batch_size = batch_size,\n","                                              class_mode = 'categorical',\n","                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n","                                              shuffle = True)"]},{"cell_type":"markdown","metadata":{"id":"Ft5U6f1Wie2R"},"source":["### **Model Building**\n","\n","* In this network, we plan to have 5 Convolutional Blocks\n","* Add first Conv2D layer with **64 filters** and a **kernel size of 2**. Use the 'same' padding and provide the **input shape = (48, 48, 1)**. Use **'relu' activation**.\n","* Add your BatchNormalization layer followed by a LeakyRelU layer with Leaky ReLU parameter of **0.1**\n","* Add MaxPooling2D layer with **pool size = 2**.\n","* Add a Dropout layer with a Dropout Ratio of **0.2**. This completes the first Convolutional block.\n","* Add a second Conv2D layer with **128 filters** and a **kernel size of 2**. Use the **'same' padding** and **'relu' activation.**\n","* Follow this up with a similar BatchNormalization, LeakyRelU, Maxpooling2D, and Dropout layer like above to complete your second Convolutional Block.\n","* Add a third Conv2D layer with **512 filters** and a **kernel size of 2**. Use the **'same' padding** and **'relu' activation.** Once again, follow it up with a BatchNormalization, LeakyRelU, Maxpooling2D, and Dropout layer to complete your third Convolutional block.\n","* Add a fourth block, with the Conv2D layer having **512 filters**.\n","* Add the fifth block, having **128 filters**.\n","* Then add your Flatten layer, followed by your Dense layers.\n","* Add your first Dense layer with **256 neurons** followed by a BatchNormalization layer, a **'relu'** Activation, and a Dropout layer. This forms your first Fully Connected block\n","* Add your second Dense layer with **512 neurons**, again followed by a BatchNormalization layer, **relu** activation, and a Dropout layer.\n","* Add your final Dense layer with 4 neurons.\n","* Compile your model with the optimizer of your choice."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37f9194d"},"outputs":[],"source":["no_of_classes = 4\n","\n","model3 = Sequential()\n","\n","# Add 1st CNN Block\n","model3.add(Conv2D(64, kernel_size=(2), padding='same', activation='relu', input_shape=(48,48,1)))\n","model3.add(BatchNormalization())\n","model3.add(LeakyReLU(alpha=0.1))\n","model3.add(MaxPooling2D(pool_size=(2)))\n","model3.add(Dropout(rate=0.2))\n","\n","# Add 2nd CNN Block\n","model3.add(Conv2D(128, kernel_size=(2), padding='same', activation='relu'))\n","model3.add(BatchNormalization())\n","model3.add(LeakyReLU(alpha=0.1))\n","model3.add(MaxPooling2D(pool_size=(2)))\n","model3.add(Dropout(rate=0.2))\n","\n","# Add 3rd CNN Block\n","model3.add(Conv2D(512, kernel_size=(2), padding='same', activation='relu'))\n","model3.add(BatchNormalization())\n","model3.add(LeakyReLU(alpha=0.1))\n","model3.add(MaxPooling2D(pool_size=(2)))\n","model3.add(Dropout(rate=0.2))\n","\n","# Add 4th CNN Block\n","model3.add(Conv2D(512, kernel_size=(2), padding='same', activation='relu'))\n","model3.add(BatchNormalization())\n","model3.add(LeakyReLU(alpha=0.1))\n","model3.add(MaxPooling2D(pool_size=(2)))\n","model3.add(Dropout(rate=0.2))\n","\n","# Add 5th CNN Block\n","model3.add(Conv2D(128, kernel_size=(2), padding='same', activation='relu'))\n","model3.add(BatchNormalization())\n","model3.add(LeakyReLU(alpha=0.1))\n","model3.add(MaxPooling2D(pool_size=(2)))\n","model3.add(Dropout(rate=0.2))\n","\n","model3.add(Flatten())\n","\n","# First fully connected layer\n","model3.add(Dense(256, activation='relu'))\n","model3.add(BatchNormalization())\n","model3.add(Dropout(rate=0.2))\n","\n","# Second fully connected layer\n","model3.add(Dense(512, activation='relu'))\n","model3.add(BatchNormalization())\n","model3.add(Dropout(rate=0.2))\n","\n","model3.add(Dense(no_of_classes, activation = 'softmax'))"]},{"cell_type":"markdown","metadata":{"id":"fyc0B--hwTHS"},"source":["### **Compiling and Training the Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0edabf52"},"outputs":[],"source":["from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n","\n","epochs = 35\n","\n","steps_per_epoch = train_set.n//train_set.batch_size\n","validation_steps = validation_set.n//validation_set.batch_size\n","\n","checkpoint = ModelCheckpoint(\"model3.h5\", monitor = 'val_accuracy',\n","                            save_weights_only = True, model = 'max', verbose = 1)\n","\n","reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, min_lr = 0.0001 , model = 'auto')\n","\n","callbacks = [checkpoint, reduce_lr]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYDJwZWmKSK6"},"outputs":[],"source":["# Write your code to compile your model3. Use categorical crossentropy as the loss function, Adam Optimizer with 0.003 learning rate, and set metrics to 'accuracy'.\n","\n","model3.compile(optimizer=Adam(learning_rate = 0.003), loss=categorical_crossentropy, metrics='accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_tB9HX5sKjUL"},"outputs":[],"source":["# Write your code to fit your model. Use train_set as the training data and validation_set as the validation data. Train your model for 35 epochs.\n","\n","history = model3.fit(train_set, validation_data = validation_set, epochs = 35)"]},{"cell_type":"markdown","metadata":{"id":"BbAqrAQQVjIR"},"source":["### **Evaluating the Model on Test Set**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uO26AYRuVm7F"},"outputs":[],"source":["# Write your code to evaluate the model performance on the test set\n","model3_eval = model3.evaluate(test_set) \n","\n","# Model.evaluate() outputs the test loss and the test accuracy, hence:\n","print('Model3 Test loss:', model3_eval[0]) \n","print('Model3 Test accuracy:', model3_eval[1])"]},{"cell_type":"markdown","metadata":{"id":"81uYGSmHwxfD"},"source":["**Observations and Insights:__**"]},{"cell_type":"markdown","metadata":{"id":"GNWc6agwxJ_z"},"source":["### **Plotting the Confusion Matrix for the chosen final model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SFTRyIk-yjoQ"},"outputs":[],"source":["# Plot the confusion matrix and generate a classification report for the model\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","test_set = datagen_test.flow_from_directory(folder_path + \"test\",\n","                                                              target_size = (img_size,img_size),\n","                                                              color_mode = 'grayscale',\n","                                                              batch_size = 128,\n","                                                              class_mode = 'categorical',\n","                                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n","                                                              shuffle = True) \n","test_images, test_labels = next(test_set)\n","\n","# Write the name of your chosen model in the blank\n","pred = model3.predict(test_images)\n","pred = np.argmax(pred, axis = 1) \n","y_true = np.argmax(test_labels, axis = 1)\n","\n","# Printing the classification report\n","print(classification_report(test_labels, pred))\n","\n","# Plotting the heatmap using confusion matrix\n","cm = confusion_matrix(y_true, pred)\n","plt.figure(figsize = (8, 5))\n","sns.heatmap(cm, annot = True,  fmt = '.0f', xticklabels = ['happy', 'sad', 'neutral', 'surprise'], yticklabels = ['happy', 'sad', 'neutral', 'surprise'])\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"LGgvpOrP8q_x"},"source":["**Observations and Insights:__**"]},{"cell_type":"markdown","metadata":{"id":"6s_baiF_KllW"},"source":["## **Conclusion:____________**"]},{"cell_type":"markdown","metadata":{"id":"MEZPA_mN0tUo"},"source":["### **Insights**\n","\n","### **Refined insights**:\n","- What are the most meaningful insights from the data relevant to the problem?\n","\n","### **Comparison of various techniques and their relative performance**:\n","- How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?\n","\n","### **Proposal for the final solution design**:\n","- What model do you propose to be adopted? Why is this the best solution to adopt?"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}